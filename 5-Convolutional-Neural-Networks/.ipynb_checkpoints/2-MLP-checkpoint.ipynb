{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flattening Input Images\n",
    "\n",
    "Recall that MLP's only take vectors as an input. Therefore, in order to use an MLP on images, we first have to convert any image array into a vector. This process is called **flattening**. Let's consider a simple example from a MNIST dataset where we have an image with number 7:\n",
    "\n",
    "<img src='assets/flattening-example-1.png' width=\"500\">\n",
    "\n",
    "Instead of representing this as a 4-by-4 matrix, we construct a vector with 16 entries. The first 4 entries of the vector correspond to the first row of the matrix, the second 4 entries of the vector correspond to the second row of the matrix and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP Structure & Class Scores\n",
    "\n",
    "At this point our MNIST images have been converted into a vector with 784 entries. Recall that original MNIST images are 28-by-28 arrays. We also know that we want our output layer to distinguish between 10 digit types, 0 through 9. Therefore, we want the last layer to have 10 nodes.\n",
    "\n",
    "Our model will take a flattened image and produce 10 output values, one for each possible class. These output values are often called **class scores**.\n",
    "\n",
    "> A **high** class score indicates that the network is very **certain** that the given image falls into a certain class.\n",
    "\n",
    "\n",
    "You can imagine that the class score for a handwritten digit 3 will have the highest score for the class 3. But it also may have a small score for 8 or any other class that looks kind of similar in shape to a 3.  \n",
    "\n",
    "<img src='assets/class-score.png' width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hidden Layers\n",
    "\n",
    "In between an input and an output layer are hidden layers.\n",
    "\n",
    "<img src='assets/hidden-layer.png' width=\"500\">\n",
    "\n",
    "Some take-aways as you're designing your architecture:\n",
    "\n",
    "* More hidden layers generally means more ability to recognize complex patterns\n",
    "* One or more hidden layers should generally work fine for small images\n",
    "* Keep looking for a resource or two that appeals to you\n",
    "* Try out different models in code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss\n",
    "\n",
    "How will the network learn to predict the correct class for each image in the MNIST data?\n",
    "\n",
    "Take this example of a 2:\n",
    "\n",
    "<img src='assets/loss.png' width=\"500\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
