{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Networks\n",
    "\n",
    "**GENERAL IDEA:** Convolutional neural networks (ConvNets) can look at images as a whole and learn to identify spatial patterns. Such patterns include prominent colors or shapes or whether a texture is fuzzy or smooth. \n",
    "\n",
    "<img src='assets/features-convnet.png' width=\"500\">\n",
    "\n",
    "\n",
    "\n",
    "The shapes and colors that define any image or any object in an image are called **features**. ConvNets will learn to identify those features and therefore can be used for image classification or object detection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST Database\n",
    "\n",
    "Let's begin by examining how deep learning can be used to recognize a single object in an image. In this example, we want to design an image classifier that takes in an image with a hand-written number and produces a predicted class for that number. Ideally this class correctly identifies the input.\n",
    "\n",
    "<img src='assets/simple-cnn.png' width=\"500\">\n",
    "\n",
    "\n",
    "**MNIST**: To build this algorithm, we will use MNIST Database, which contains 70,000 grey-scale images of handwritten digits, ranging from 0 to 9. This database is probably one of the most famous databases in the fields of machine learning and deep learning. \n",
    "\n",
    "However, if you look over a small sample of data you might notice that some digits are more legible than others. For instance, the digit 3 at the bottom could easily pass for an 8. Similarly, some 1's could pass for 7's.\n",
    "\n",
    "<img src=\"assets/mnist-digit-3.png\" width=\"500\">\n",
    "\n",
    "Even with these subtleties, for us humans the task of identifying digits is relatively straightforward. Similarly, we want to design an algorithm that too can accurately distinguish between each of these numbers. The first step in recognizing patterns in images is learning how images are seen by a computer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How Computers Interpret Images\n",
    "\n",
    "Any grey-scale image is interpreted by a computer as an array or a grid of values where each grid cell is referred to as a pixel. Each pixel takes on a numerical value ranging from 0 to 255. Each image in the MNIST database is 28 pixels tall and 28 pixels wide and therefore it's understood by a computer as a 28-by-28 array. In a grey-scale image white pixels are encoded as values 255 and black pixels are encoded as 0. Grey pixels fall somewhere in between with lighter gradients being closer to 255 and darker gradients falling closer to 0. \n",
    "\n",
    "These MNIST images have gone through a quick pre-processing. They've been **normalized** so that each image has pixel values in the range between 0 and 1. \n",
    "\n",
    "<img src=\"assets/0-to-255.png\" width=\"500\">\n",
    "<pre>\n",
    "\n",
    "</pre>\n",
    "\n",
    "\n",
    "<img src=\"assets/0-to-1.png\" width=\"500\">\n",
    "<pre>\n",
    "\n",
    "</pre>\n",
    "\n",
    "### Why do we normalize our input images?\n",
    "\n",
    "**Normalization** is a common practice in many deep learning techniques since it helps the algorithm train faster. The reason we typically want normalized pixel values is because neural networks rely on gradient calculations. These networks are trying to learn how important a certain pixel should be in determining a correct class for the image and normalizing the pixel values helps these gradient calculations stay consistent as opposed to getting too large that they prevent the network from training. By normalizing all of our inputs to a standard scale, we are allowing the network to more quickly learn the optimal parameters for each input node.\n",
    "\n",
    "\n",
    "<img src=\"assets/normalized-vs-unnormalized.png\" width=\"700\">\n",
    "\n",
    "<div align=\"center\">\n",
    "<em> Gradient descent: unnormalized versus normalized level curves. </em>\n",
    "</div>\n",
    "\n",
    "\n",
    "<pre>\n",
    "\n",
    "</pre>\n",
    "\n",
    "### Is normalization always bounded by [0, 1]?\n",
    "\n",
    "No. Indeed, you might opt for a different normalization strategy when working with features different than image data. A common strategy is to ensure that the inputs are roughly in the range from -1 to 1 to avoid strange mathematical artifacts associated with floating point number precision. This happens because computers lose accuracy when performing math operations on really large or really small numbers. Also bounding the input data by the interval [-1, 1] ensures the default parameters for your neural network, such as learning rates, will likely be well-suited for your data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's next?\n",
    "\n",
    "So now that we have normalized data, how might we approach the task of classifying these images? \n",
    "\n",
    "One classification method that we already learned in Lesson 4 is a **multi-layer perceptron network (MLP)**, also commonly called a **feed-forward network**. \n",
    "\n",
    "Another method is **convolutional neural network**. We'll explore and compare these networks in more detail in the following notebooks in this lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
